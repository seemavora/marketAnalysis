{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_samples,silhouette_score, davies_bouldin_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import boxcox, skew\n",
    "from sklearn.decomposition import PCA, KernelPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hacForNumClusters(X,n):\n",
    "    for cluster_num in range(2,n):\n",
    "        hac(X,cluster_num)\n",
    "        \n",
    "def hac(X,cluster_num):\n",
    "    hac = AgglomerativeClustering(n_clusters = cluster_num)\n",
    "    labels = hac.fit_predict(X)\n",
    "    sil = silhouette_score(X, labels)\n",
    "    db = davies_bouldin_score(X, labels)\n",
    "    print('clus {}: {}, {}'.format(cluster_num, sil, db))\n",
    "    return labels\n",
    "        \n",
    "def cluster(filepath, num_clus, mult=False):\n",
    "    df = pd.read_csv(filepath)\n",
    "    df = df.drop(['Bios'], axis=1)\n",
    "    \n",
    "    X = df.to_numpy()\n",
    "    #minmax scaling\n",
    "    X_minmax = MinMaxScaler().fit_transform(X)\n",
    "    \n",
    "    #dimensionality reduction\n",
    "    pca = PCA(n_components = 0.99)\n",
    "    X = pca.fit_transform(X_minmax)\n",
    "    \n",
    "    if mult:\n",
    "        hacForNumClusters(X,num_clus)\n",
    "    else:\n",
    "        labels = hac(X,num_clus)\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset 1\n",
      "clus 2: 0.1311097924548254, 2.523718796851532\n",
      "clus 3: 0.11350183171234078, 2.2757643143609925\n",
      "clus 4: 0.14534076344714095, 2.3041647128305023\n",
      "clus 5: 0.12320377464402427, 2.121339691574551\n",
      "clus 6: 0.1275179232263156, 2.0207430460933256\n",
      "clus 7: 0.14704446279755468, 2.0778900347390574\n",
      "clus 8: 0.16314571503828834, 2.0841849447444365\n",
      "clus 9: 0.1504842018850041, 2.1128459750676942\n",
      "clus 10: 0.14372754804549118, 2.0748823733230566\n",
      "clus 11: 0.12967490803579237, 2.077398102070468\n",
      "clus 12: 0.11832964096403796, 2.1589801052345945\n",
      "clus 13: 0.1173143982540348, 2.2308298722974507\n",
      "clus 14: 0.11125248853191569, 2.2778935785983645\n",
      "clus 15: 0.10580318411999981, 2.277235846905591\n",
      "clus 16: 0.10658404563054125, 2.2952460158294894\n",
      "clus 17: 0.10665230251282798, 2.2283954064427185\n",
      "clus 18: 0.10697184244834382, 2.1831869212699657\n",
      "clus 19: 0.10488701755371797, 2.2158874283456726\n",
      "clus 20: 0.10442376431722247, 2.226255295150084\n",
      "clus 21: 0.10440408669174732, 2.1774232022437423\n",
      "clus 22: 0.10532728064068711, 2.1728528447884528\n",
      "clus 23: 0.10717349224265238, 2.123088619954096\n",
      "clus 24: 0.10742674841966915, 2.094985659739995\n",
      "clus 25: 0.10805810303468034, 2.0489830174030463\n",
      "clus 26: 0.108781093246757, 2.0080926182032344\n",
      "clus 27: 0.10973176893663779, 1.981048777597585\n",
      "clus 28: 0.11015396770417946, 1.9664597319521884\n",
      "clus 29: 0.1115535414887823, 1.9482379735422741\n",
      "dataset 2\n",
      "clus 2: 0.1321291017182328, 2.508192279203839\n",
      "clus 3: 0.11679039332177331, 2.2774538329422813\n",
      "clus 4: 0.141409960181152, 2.3340601362024023\n",
      "clus 5: 0.12707227434974308, 2.170955379846367\n",
      "clus 6: 0.13121320584657373, 2.1709523361382277\n",
      "clus 7: 0.14524232937376802, 2.113164730565365\n",
      "clus 8: 0.1544244944427472, 2.1163278440328614\n",
      "clus 9: 0.14716009202516966, 2.1128960796232428\n",
      "clus 10: 0.13312655717052557, 2.1389199981523945\n",
      "clus 11: 0.12958252171294646, 2.111347588499075\n",
      "clus 12: 0.12023369440769298, 2.1310678055360683\n",
      "clus 13: 0.11548832035753, 2.147868791826088\n",
      "clus 14: 0.11400557315848174, 2.181227439859648\n",
      "clus 15: 0.11371705690249874, 2.170481646979941\n",
      "clus 16: 0.11447961106107939, 2.1774493241190758\n",
      "clus 17: 0.11397147111080758, 2.208161929077958\n",
      "clus 18: 0.1123410932084023, 2.166862466553796\n",
      "clus 19: 0.11290300461410456, 2.127478112289118\n",
      "clus 20: 0.11061651806648103, 2.1267627449384143\n",
      "clus 21: 0.11110566808429014, 2.1040729805102414\n",
      "clus 22: 0.11198527840974755, 2.0382885607508268\n",
      "clus 23: 0.11333056639844037, 2.0136725742420793\n",
      "clus 24: 0.11374409407075486, 1.9684474298915315\n",
      "clus 25: 0.1134633573099532, 1.9471486071186188\n",
      "clus 26: 0.11402377507041876, 1.9175616654530303\n",
      "clus 27: 0.1125737388779866, 1.8896108368181925\n",
      "clus 28: 0.11533016696847874, 1.8893193411847216\n",
      "clus 29: 0.115489820577128, 1.8593263432749494\n"
     ]
    }
   ],
   "source": [
    "print('dataset 1')\n",
    "labels1 = cluster('./TEST1.csv',30,True)\n",
    "\n",
    "print('dataset 2')\n",
    "labels2 = cluster('./TEST2.csv',30,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset 1\n",
      "clus 8: 0.16314571503828834, 2.0841849447444365\n",
      "dataset 2\n",
      "clus 8: 0.1544244944427472, 2.1163278440328614\n"
     ]
    }
   ],
   "source": [
    "print('dataset 1')\n",
    "labels1 = cluster('./TEST1.csv',8)\n",
    "\n",
    "print('dataset 2')\n",
    "labels2 = cluster('./TEST2.csv',8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#os.mkdir(os.getcwd() + '/' + someWord)\n",
    "def please(filepath, labels, n, someWord):\n",
    "    df_ori = pd.read_csv(filepath)\n",
    "    df_ori['cluster #'] = labels\n",
    "    #os.mkdir(os.getcwd() + '/' + someWord)\n",
    "    \n",
    "    \n",
    "    for cluster in range(n):\n",
    "        yes = df_ori[df_ori['cluster #'] == cluster]\n",
    "        filename = '{}/{}.csv'.format(someWord, str(cluster))\n",
    "        yes.to_csv(filename)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "please('./TEST1.csv',labels1,8,'woohoo1')\n",
    "\n",
    "please('./TEST2.csv',labels2,8,'woohoo2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clustering the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "def nlp_clus(filename, n, desc=False):\n",
    "    df = pd.read_csv(filename)\n",
    "    # Instantiating the Vectorizer, experimenting with both\n",
    "    vectorizer = CountVectorizer()\n",
    "    #vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Fitting the vectorizer to the Bios\n",
    "    x = vectorizer.fit_transform(df['Bios'])\n",
    "\n",
    "    # Creating a new DF that contains the vectorized words\n",
    "    df_wrds = pd.DataFrame(x.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "    # Concating the words DF with the original DF\n",
    "    new_df = pd.concat([df, df_wrds], axis=1)\n",
    "\n",
    "    # Dropping the Bios because it is no longer needed in place of vectorization\n",
    "    new_df.drop('Bios', axis=1, inplace=True)\n",
    "\n",
    "    # Instantiating PCA\n",
    "    pca = PCA()\n",
    "\n",
    "    # Fitting and Transforming the DF\n",
    "    df_pca = pca.fit_transform(new_df)\n",
    "\n",
    "    # Reducing the dataset to the number of features determined before\n",
    "    pca = PCA(n_components=0.99)\n",
    "\n",
    "    # Fitting and transforming the dataset to the stated number of features and creating a new DF\n",
    "    df_pca = pca.fit_transform(new_df)\n",
    "\n",
    "    # Seeing the variance ratio that still remains after the dataset has been reduced\n",
    "    print(pca.explained_variance_ratio_.cumsum()[-1])\n",
    "    \n",
    "    labels = cluster(filename,n,False)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_cluster_for_cluster_spec(dir_spec):\n",
    "    dirname = '{}/{}'.format(os.getcwd(),dir_spec)\n",
    "    for filename in os.listdir(dirname):\n",
    "        labels = nlp_clus('{}/{}'.format(dirname, filename), 30, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9984505754157542\n",
      "clus 2: 0.09281559688201381, 2.648893675067007\n",
      "clus 3: 0.09370652810575969, 2.278291998173438\n",
      "clus 4: 0.09101351537390083, 2.0695269875470514\n",
      "clus 5: 0.10545131959603032, 1.8744987677574483\n",
      "clus 6: 0.10903373482777731, 1.6883502928282772\n",
      "clus 7: 0.12510213330397915, 1.6182800098023566\n",
      "clus 8: 0.12397210235821858, 1.5269026827052337\n",
      "clus 9: 0.12545079115807076, 1.47782035222056\n",
      "clus 10: 0.13288180286111717, 1.4111439477308152\n",
      "clus 11: 0.1346431371650235, 1.439164905359859\n",
      "clus 12: 0.1453484444361042, 1.393878611039578\n",
      "clus 13: 0.15573235784162306, 1.3475912422785956\n",
      "clus 14: 0.15796511180207543, 1.274121638704496\n",
      "clus 15: 0.1619404112575749, 1.2388273893326451\n",
      "clus 16: 0.1670909949198595, 1.20947030782854\n",
      "clus 17: 0.1726345774801811, 1.175631765058812\n",
      "clus 18: 0.18195178382718852, 1.1385213864972539\n",
      "clus 19: 0.17172818856043742, 1.0918516410460555\n",
      "clus 20: 0.16776577438881243, 1.0404600794923426\n",
      "clus 21: 0.15872599255240785, 1.0156284685471753\n",
      "clus 22: 0.15970967967028227, 1.0060650688592663\n",
      "clus 23: 0.15849173472345252, 0.9765485614570167\n",
      "clus 24: 0.1598442728185135, 0.9655806124917131\n",
      "clus 25: 0.1592124812242113, 0.9374235675771331\n",
      "clus 26: 0.15796830815341778, 0.8954144979387022\n",
      "clus 27: 0.15875870433077796, 0.8914612461908228\n",
      "clus 28: 0.15810723774224691, 0.8685667153739127\n",
      "clus 29: 0.154107418954113, 0.8360583521354485\n",
      "0.9981950697614622\n",
      "clus 2: 0.1091592102882786, 2.516216685305001\n",
      "clus 3: 0.10020679604530969, 2.1112908585330206\n",
      "clus 4: 0.11717830274101666, 1.8859352192281391\n",
      "clus 5: 0.12641551836213677, 1.691815784413685\n",
      "clus 6: 0.1296160132475455, 1.5894474929998441\n",
      "clus 7: 0.14398245176685698, 1.5112851449793954\n",
      "clus 8: 0.1615334256409478, 1.386029733088523\n",
      "clus 9: 0.16148800586403764, 1.3394257235445806\n",
      "clus 10: 0.1697025788566342, 1.253699680019362\n",
      "clus 11: 0.1851970515155351, 1.1709874535329605\n",
      "clus 12: 0.18105610183502058, 1.153629436579031\n",
      "clus 13: 0.18140128692121377, 1.066237495541127\n",
      "clus 14: 0.18602177998209204, 1.0169344803581184\n",
      "clus 15: 0.17573158957667706, 0.9766556467295829\n",
      "clus 16: 0.17443359068001438, 0.9599929379673748\n",
      "clus 17: 0.17607185349653887, 0.9333160181377731\n",
      "clus 18: 0.17202702427227023, 0.8942268503858778\n",
      "clus 19: 0.17447283254722168, 0.8565338016613355\n",
      "clus 20: 0.16337573446297737, 0.8165351222701366\n",
      "clus 21: 0.15683723276184575, 0.7818749571849262\n",
      "clus 22: 0.15104975107018057, 0.7490868947701756\n",
      "clus 23: 0.14561503135065945, 0.7116820366135016\n",
      "clus 24: 0.133598967115348, 0.6747895481334019\n",
      "clus 25: 0.12252121219188954, 0.6460293407196142\n",
      "clus 26: 0.11391328900830995, 0.6155188164336417\n",
      "clus 27: 0.10612660339324483, 0.5994280490494469\n",
      "clus 28: 0.09783832208392532, 0.5794755623854269\n",
      "clus 29: 0.08976594289820691, 0.5534599983100994\n",
      "0.9983426331134531\n",
      "clus 2: 0.11724833569897515, 2.4037836910470496\n",
      "clus 3: 0.11754653752984923, 2.0309680928858955\n",
      "clus 4: 0.12032043364542454, 1.869465571556204\n",
      "clus 5: 0.11790479672973722, 1.765869393955342\n",
      "clus 6: 0.12603021962120525, 1.5921898207749907\n",
      "clus 7: 0.12689848053272976, 1.4967364493987447\n",
      "clus 8: 0.13075101830034194, 1.4192481501306315\n",
      "clus 9: 0.12863465081034173, 1.4342367369925493\n",
      "clus 10: 0.12781740344047646, 1.4781585702457045\n",
      "clus 11: 0.1296134574224499, 1.4498911275979507\n",
      "clus 12: 0.14201979866951125, 1.3678832799944465\n",
      "clus 13: 0.15913571100120488, 1.298049833771304\n",
      "clus 14: 0.16257883489208935, 1.251327337963522\n",
      "clus 15: 0.16638081959384457, 1.2262305001130995\n",
      "clus 16: 0.1684786956405257, 1.1959991971081072\n",
      "clus 17: 0.16798335983954682, 1.13660099333997\n",
      "clus 18: 0.16507047409115336, 1.103833725358581\n",
      "clus 19: 0.16333634970681482, 1.0485968600512259\n",
      "clus 20: 0.15887581002456247, 0.9922542492455525\n",
      "clus 21: 0.1573315727801965, 0.9423011561719405\n",
      "clus 22: 0.15141235890190918, 0.8988633498835626\n",
      "clus 23: 0.15021894588174284, 0.9047754853303722\n",
      "clus 24: 0.14542717824169327, 0.8609907806429421\n",
      "clus 25: 0.14559660023702506, 0.8587476278914059\n",
      "clus 26: 0.1413342781065359, 0.8158519496482513\n",
      "clus 27: 0.13661019393458565, 0.7604980659443029\n",
      "clus 28: 0.130527922326256, 0.7185590174119364\n",
      "clus 29: 0.12861940088230003, 0.698859403104032\n",
      "0.9982374596075535\n",
      "clus 2: 0.11523996759028828, 2.4138731017484703\n",
      "clus 3: 0.11561564172838618, 1.9911081115975902\n",
      "clus 4: 0.11588232817844406, 1.897534368191622\n",
      "clus 5: 0.11049931511033673, 1.7417382087336168\n",
      "clus 6: 0.1293852258713761, 1.5809704792442665\n",
      "clus 7: 0.13752901555891803, 1.475159272955036\n",
      "clus 8: 0.13804288182688487, 1.4328653021113853\n",
      "clus 9: 0.14439290022829837, 1.3171209348814348\n",
      "clus 10: 0.14939086757518524, 1.263705536586376\n",
      "clus 11: 0.15733850725030804, 1.277173855416215\n",
      "clus 12: 0.16520838465752838, 1.2335253916245195\n",
      "clus 13: 0.17484999058010328, 1.1921985306798872\n",
      "clus 14: 0.1694232419206311, 1.1792467175829413\n",
      "clus 15: 0.16878933984017955, 1.122150296857318\n",
      "clus 16: 0.17100278674813066, 1.0484763688776133\n",
      "clus 17: 0.1617302575256987, 1.0676517737062041\n",
      "clus 18: 0.15762851090770136, 0.9949146051670432\n",
      "clus 19: 0.15600589552908953, 0.9307930355720777\n",
      "clus 20: 0.15179269363487294, 0.9099194549166676\n",
      "clus 21: 0.14716115833347412, 0.8969703005836668\n",
      "clus 22: 0.14643426549614477, 0.8513207772923373\n",
      "clus 23: 0.14775202167896662, 0.8453465491193546\n",
      "clus 24: 0.1487348980090857, 0.8208727867574183\n",
      "clus 25: 0.14484968910536367, 0.7905972324262452\n",
      "clus 26: 0.14433402864111836, 0.7566674876242525\n",
      "clus 27: 0.1425769911533467, 0.7202634601966749\n",
      "clus 28: 0.1300821724310729, 0.6871923370919542\n",
      "clus 29: 0.12582887774702092, 0.6643180430090617\n",
      "0.9981747004738313\n",
      "clus 2: 0.11297952948858485, 2.5765899436941933\n",
      "clus 3: 0.10277595290084475, 2.143566518469489\n",
      "clus 4: 0.10533616233608921, 2.006522227097546\n",
      "clus 5: 0.1232967478644891, 1.833134098767894\n",
      "clus 6: 0.13555869750208066, 1.6861082486677625\n",
      "clus 7: 0.14815051696387668, 1.5778625296351148\n",
      "clus 8: 0.15783071433467147, 1.4807775334278381\n",
      "clus 9: 0.15220763095245296, 1.3734364866711342\n",
      "clus 10: 0.16198652437894354, 1.2923519615790942\n",
      "clus 11: 0.1742910534634068, 1.2917960045891435\n",
      "clus 12: 0.18720993521995702, 1.2071249839396323\n",
      "clus 13: 0.19566331507273935, 1.1771303285318468\n",
      "clus 14: 0.20601319162556028, 1.1076874651044288\n",
      "clus 15: 0.2135973368109641, 1.0588129070047507\n",
      "clus 16: 0.20893669500442613, 1.066851794468504\n",
      "clus 17: 0.20482776479836176, 1.1090098734605716\n",
      "clus 18: 0.20626571072509248, 1.0597603504391662\n",
      "clus 19: 0.2001163330626664, 1.0142056241860467\n",
      "clus 20: 0.20091141261251153, 0.9293683823913339\n",
      "clus 21: 0.2118993254304537, 0.907160458353511\n",
      "clus 22: 0.20882882349364437, 0.8728072385773319\n",
      "clus 23: 0.21182672927343535, 0.836394820334167\n",
      "clus 24: 0.20488987745696982, 0.8065171288223407\n",
      "clus 25: 0.20154192241313126, 0.7929097997351628\n",
      "clus 26: 0.2022439462686685, 0.7728102997382806\n",
      "clus 27: 0.20114062036166122, 0.7417070759540316\n",
      "clus 28: 0.19676332185557588, 0.7082118008583266\n",
      "clus 29: 0.19085961532742143, 0.6831702949062985\n",
      "0.9982651981056483\n",
      "clus 2: 0.10138866005350504, 2.51753387590617\n",
      "clus 3: 0.1025292299855928, 2.1968710614723563\n",
      "clus 4: 0.1033965807912524, 1.8812415706577639\n",
      "clus 5: 0.10898990092884499, 1.9812443134136593\n",
      "clus 6: 0.1149184029678026, 1.7981218152731941\n",
      "clus 7: 0.12325711106577208, 1.7193297083876342\n",
      "clus 8: 0.12206424863621944, 1.6445555264490221\n",
      "clus 9: 0.12932649558160847, 1.5538195643868253\n",
      "clus 10: 0.12566822680848344, 1.4744527724495249\n",
      "clus 11: 0.1329813470858641, 1.4096601355445202\n",
      "clus 12: 0.14014510679101175, 1.3552647105080553\n",
      "clus 13: 0.14370662177128515, 1.3401274622635868\n",
      "clus 14: 0.14799242730965584, 1.2379436383387632\n",
      "clus 15: 0.1568929279275024, 1.2046175578597589\n",
      "clus 16: 0.16336755353427018, 1.1957707066304928\n",
      "clus 17: 0.15664316162235853, 1.1813171302190946\n",
      "clus 18: 0.1630388327731876, 1.1214420060416417\n",
      "clus 19: 0.1672194567773664, 1.1043133832351402\n",
      "clus 20: 0.16728855140831528, 1.0616045541999193\n",
      "clus 21: 0.16441455972009128, 1.0199647503610973\n",
      "clus 22: 0.16984446632931574, 0.9970569664598815\n",
      "clus 23: 0.1766010107692107, 0.9639382014037289\n",
      "clus 24: 0.17739352893613253, 0.9253902554043844\n",
      "clus 25: 0.1740235758003404, 0.8942620278459482\n",
      "clus 26: 0.16659959512065498, 0.8613429263341298\n",
      "clus 27: 0.16726022767519264, 0.843767070659725\n",
      "clus 28: 0.16354522831706025, 0.806196067265364\n",
      "clus 29: 0.15510577435341025, 0.7548126702539547\n",
      "0.9983595432185679\n",
      "clus 2: 0.13929924402530602, 2.246897875868272\n",
      "clus 3: 0.15206221472811332, 1.767524170536311\n",
      "clus 4: 0.14906347494395034, 1.8254858116281385\n",
      "clus 5: 0.15386376264412008, 1.6133089787727122\n",
      "clus 6: 0.1569057068903469, 1.6640910224331338\n",
      "clus 7: 0.16913724850775635, 1.5295128551413042\n",
      "clus 8: 0.17837445372984603, 1.424032549350204\n",
      "clus 9: 0.19016961253431244, 1.3529423596630545\n",
      "clus 10: 0.20384118247536603, 1.2939073480843937\n",
      "clus 11: 0.20840347786320465, 1.2492880736854604\n",
      "clus 12: 0.21819468920306304, 1.1444699118169452\n",
      "clus 13: 0.22047289314908597, 1.0917657934359388\n",
      "clus 14: 0.22167675245771115, 1.046311330028281\n",
      "clus 15: 0.2202038011678859, 1.0534450743433552\n",
      "clus 16: 0.22380396703370906, 1.0507055201577415\n",
      "clus 17: 0.2241934345058658, 0.998283202719694\n",
      "clus 18: 0.21875228501405597, 0.9545725337987433\n",
      "clus 19: 0.21666840197055673, 0.8895725578594476\n",
      "clus 20: 0.2220841443351534, 0.8248887964527611\n",
      "clus 21: 0.21607373340258465, 0.7697051010297946\n",
      "clus 22: 0.2066721081447714, 0.7374122139315652\n",
      "clus 23: 0.2026244800937162, 0.7200638583271939\n",
      "clus 24: 0.1964735656344692, 0.6846621002610854\n",
      "clus 25: 0.18690945671227238, 0.655606524560635\n",
      "clus 26: 0.1830064447953781, 0.6198340853349567\n",
      "clus 27: 0.17235469333591177, 0.605727153345044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clus 28: 0.1576120025411879, 0.6248992103455581\n",
      "clus 29: 0.1473452828841026, 0.6118456876540717\n",
      "0.9981442008155497\n",
      "clus 2: 0.1331121076840002, 1.9534263365076359\n",
      "clus 3: 0.12658051260088826, 2.0375664402877494\n",
      "clus 4: 0.13170085036247725, 1.8398891809192701\n",
      "clus 5: 0.13737831498438366, 1.6913706628214111\n",
      "clus 6: 0.15259203375895006, 1.5682499578551372\n",
      "clus 7: 0.1681001443873215, 1.4498921031566105\n",
      "clus 8: 0.17419856798784353, 1.4759001177687279\n",
      "clus 9: 0.1834649911300235, 1.3706545925556413\n",
      "clus 10: 0.19876450164764617, 1.3060676297655627\n",
      "clus 11: 0.20074229565414525, 1.218636084886699\n",
      "clus 12: 0.20527147483518488, 1.1926419645207047\n",
      "clus 13: 0.21589550222830883, 1.1394508344964385\n",
      "clus 14: 0.2136601523654786, 1.0952281991579258\n",
      "clus 15: 0.2141745483414077, 1.0844416497798062\n",
      "clus 16: 0.20994476808280835, 1.0283779351971862\n",
      "clus 17: 0.20956508650447392, 0.9854024413943508\n",
      "clus 18: 0.20946242583281782, 0.91139043876364\n",
      "clus 19: 0.20554386473114397, 0.8704449648200869\n",
      "clus 20: 0.20625129077161744, 0.8825763171500111\n",
      "clus 21: 0.20798460435071256, 0.8636900022476101\n",
      "clus 22: 0.2053859877577014, 0.822214826457492\n",
      "clus 23: 0.20002574296213196, 0.7749569655720862\n",
      "clus 24: 0.19713841667480328, 0.7483014332854632\n",
      "clus 25: 0.19639720045747688, 0.7316389400023483\n",
      "clus 26: 0.19142673109294164, 0.6847855665487584\n",
      "clus 27: 0.18695102068454755, 0.6403720488618947\n",
      "clus 28: 0.18136019357009603, 0.6168035141386429\n",
      "clus 29: 0.18054178419143652, 0.5707700220779764\n"
     ]
    }
   ],
   "source": [
    "nlp_cluster_for_cluster_spec('./woohoo1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_cluster_for_cluster(dir_spec, n):\n",
    "    dirname = '{}/{}'.format(os.getcwd(),dir_spec)\n",
    "    for filename in os.listdir(dirname):\n",
    "        path = '{}/{}'.format(dirname, filename)\n",
    "        labels = nlp_clus(path, n, False)\n",
    "        print(labels)\n",
    "        please(filename,labels,n,'woohoo_{}'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9984505754157542\n",
      "clus 15: 0.1619404112575749, 1.2388273893326451\n",
      "[ 8  8  9  0 12  9  2  9  0  0  0  3  2  0  0 13 11  3 13  3  2  2  8  6\n",
      " 11  1 12  6  2  0  6  1 13  3  5  7  7  4  3 10  7 10  5  5  1 10  1 10\n",
      "  4  1  7 11  4 14  5 14  4]\n",
      "0.9981950697614622\n",
      "clus 15: 0.17573158957667706, 0.9766556467295829\n",
      "[ 5 11  1  6  7  5  1 11  3 11  1  8  4  7  6 14  3  4  8  9  2 10  1  2\n",
      " 10  8  3  4 13  0  2 10 13  0  6  9 12  0  2  0]\n",
      "0.9983426331134531\n",
      "clus 15: 0.16638081959384457, 1.2262305001130995\n",
      "[ 9  2  3  3  3  5 12  8  9  5  3  8  4 12  9 13  8  4 13 10  2  4  1 14\n",
      "  4 14  4 13 10  0  1  2  6  7  6  6  0 11  6  1  1  6 11  7  0  1  0]\n",
      "0.9982374596075535\n",
      "clus 15: 0.16878933984017955, 1.122150296857318\n",
      "[ 8  6  5  8  6  5 13  7  0  6  6 12 13  7 11  6  4  0 13  4  7  3  2  2\n",
      "  0 11  3  2  3  4  2  4  9 11 12 10  0  3  4  2 10  9  2  1  9 14 10  1]\n",
      "0.9981747004738313\n",
      "clus 15: 0.2135973368109641, 1.0588129070047507\n",
      "[ 6  5  6  4  5 11  0  5  7 13  6  0  0 11  0  0  0  0 13  3 11  6  8  3\n",
      "  8  4  4  4  2  2  7  9  2 10  8  2  2  2 10  3 14  1  2  9  2 10  9 14\n",
      " 12  1  8 12  1]\n",
      "0.9982651981056483\n",
      "clus 15: 0.1568929279275024, 1.2046175578597589\n",
      "[ 3  3  0  0  3  3  0  3  1  1  0 14 12  1  5  5 14  7  2 11  0  1  0 11\n",
      " 11  9  6  1  1  7  2 12  2 12 12  6  6 11  4  9  7 10 10  5  2  7  4  9\n",
      " 13  8  4  8  8]\n",
      "0.9983595432185679\n",
      "clus 15: 0.2202038011678859, 1.0534450743433552\n",
      "[ 4 12  1  4 12  1  8 14  1  1  7  6  1 14  7  8  6 14  0  6  7  9  9 11\n",
      "  2  0 13 11 10  8  0  5  5 10  0  2  0  3 10  5 13  3  2 10  9]\n",
      "0.9981442008155497\n",
      "clus 15: 0.2141745483414077, 1.0844416497798062\n",
      "[ 1  0  0  5  9  0 13  8  5  8  7  9  7  5 13 11  4 11  9  8  5  8  3  4\n",
      "  3  3  3 10  1 14  4  3 10  2  4  2 10  2 14  4 12  3  2 10 12  6  6]\n"
     ]
    }
   ],
   "source": [
    "nlp_cluster_for_cluster('./woohoo1', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs185c",
   "language": "python",
   "name": "cs185c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
