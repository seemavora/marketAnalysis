{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_samples,silhouette_score, davies_bouldin_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import boxcox, skew\n",
    "from sklearn.decomposition import PCA, KernelPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hacForNumClusters(X,n):\n",
    "    for cluster_num in range(2,n):\n",
    "        hac(X,cluster_num)\n",
    "        \n",
    "def hac(X,cluster_num):\n",
    "    hac = AgglomerativeClustering(n_clusters = cluster_num)\n",
    "    labels = hac.fit_predict(X)\n",
    "    sil = silhouette_score(X, labels)\n",
    "    db = davies_bouldin_score(X, labels)\n",
    "    print('clus {}: {}, {}'.format(cluster_num, sil, db))\n",
    "    return labels\n",
    "        \n",
    "def cluster(filepath, num_clus, mult=False):\n",
    "    df = pd.read_csv(filepath)\n",
    "    df = df.drop(['Bios'], axis=1)\n",
    "    \n",
    "    X = df.to_numpy()\n",
    "    #minmax scaling\n",
    "    X_minmax = MinMaxScaler().fit_transform(X)\n",
    "    \n",
    "    #dimensionality reduction\n",
    "    pca = PCA(n_components = 0.99)\n",
    "    X = pca.fit_transform(X_minmax)\n",
    "    \n",
    "    if mult:\n",
    "        hacForNumClusters(X,num_clus)\n",
    "    else:\n",
    "        labels = hac(X,num_clus)\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dataset 1\n",
      "clus 2: 0.13110979245482507, 2.523718796851537\n",
      "clus 3: 0.11350183171234067, 2.27576431436099\n",
      "clus 4: 0.14534076344714092, 2.3041647128304996\n",
      "clus 5: 0.12320377464402425, 2.1213396915745486\n",
      "clus 6: 0.12751792322631578, 2.020743046093323\n",
      "clus 7: 0.14704446279755481, 2.077890034739056\n",
      "clus 8: 0.1631457150382885, 2.084184944744435\n",
      "clus 9: 0.15048420188500422, 2.1128459750676942\n",
      "clus 10: 0.14372754804549123, 2.0748823733230566\n",
      "clus 11: 0.1296749080357924, 2.0773981020704677\n",
      "clus 12: 0.118329640964038, 2.1589801052345945\n",
      "clus 13: 0.11731439825403481, 2.2308298722974502\n",
      "clus 14: 0.11125248853191574, 2.2778935785983645\n",
      "clus 15: 0.10580318411999988, 2.277235846905591\n",
      "clus 16: 0.10658404563054132, 2.2952460158294894\n",
      "clus 17: 0.10665230251282805, 2.2283954064427185\n",
      "clus 18: 0.10697184244834389, 2.183186921269965\n",
      "clus 19: 0.10488701755371804, 2.215887428345672\n",
      "clus 20: 0.10442376431722256, 2.226255295150083\n",
      "clus 21: 0.10440408669174742, 2.177423202243742\n",
      "clus 22: 0.10532728064068718, 2.172852844788452\n",
      "clus 23: 0.10717349224265246, 2.1230886199540957\n",
      "clus 24: 0.10742674841966925, 2.094985659739994\n",
      "clus 25: 0.10805810303468043, 2.048983017403046\n",
      "clus 26: 0.10878109324675704, 2.0080926182032335\n",
      "clus 27: 0.10973176893663786, 1.9810487775975847\n",
      "clus 28: 0.11015396770417955, 1.9664597319521882\n",
      "clus 29: 0.11155354148878235, 1.948237973542274\n",
      "dataset 2\n",
      "clus 2: 0.13110979245482507, 2.523718796851537\n",
      "clus 3: 0.11350183171234067, 2.27576431436099\n",
      "clus 4: 0.14534076344714092, 2.3041647128304996\n",
      "clus 5: 0.12320377464402425, 2.1213396915745486\n",
      "clus 6: 0.12751792322631578, 2.020743046093323\n",
      "clus 7: 0.14704446279755481, 2.077890034739056\n",
      "clus 8: 0.1631457150382885, 2.084184944744435\n",
      "clus 9: 0.15048420188500422, 2.1128459750676942\n",
      "clus 10: 0.14372754804549123, 2.0748823733230566\n",
      "clus 11: 0.1296749080357924, 2.0773981020704677\n",
      "clus 12: 0.118329640964038, 2.1589801052345945\n",
      "clus 13: 0.11731439825403481, 2.2308298722974502\n",
      "clus 14: 0.11125248853191574, 2.2778935785983645\n",
      "clus 15: 0.10580318411999988, 2.277235846905591\n",
      "clus 16: 0.10658404563054132, 2.2952460158294894\n",
      "clus 17: 0.10665230251282805, 2.2283954064427185\n",
      "clus 18: 0.10697184244834389, 2.183186921269965\n",
      "clus 19: 0.10488701755371804, 2.215887428345672\n",
      "clus 20: 0.10442376431722256, 2.226255295150083\n",
      "clus 21: 0.10440408669174742, 2.177423202243742\n",
      "clus 22: 0.10532728064068718, 2.172852844788452\n",
      "clus 23: 0.10717349224265246, 2.1230886199540957\n",
      "clus 24: 0.10742674841966925, 2.094985659739994\n",
      "clus 25: 0.10805810303468043, 2.048983017403046\n",
      "clus 26: 0.10878109324675704, 2.0080926182032335\n",
      "clus 27: 0.10973176893663786, 1.9810487775975847\n",
      "clus 28: 0.11015396770417955, 1.9664597319521882\n",
      "clus 29: 0.11155354148878235, 1.948237973542274\n"
     ]
    }
   ],
   "source": [
    "print('dataset 1')\n",
    "labels1 = cluster('./org.csv',30,True)\n",
    "\n",
    "print('dataset 2')\n",
    "labels2 = cluster('./org.csv',30,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dataset 1\n",
      "clus 8: 0.1631457150382885, 2.084184944744435\n",
      "dataset 2\n",
      "clus 8: 0.1631457150382885, 2.084184944744435\n"
     ]
    }
   ],
   "source": [
    "print('dataset 1')\n",
    "labels1 = cluster('./org.csv',8)\n",
    "\n",
    "print('dataset 2')\n",
    "labels2 = cluster('./org.csv',8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#os.mkdir(os.getcwd() + '/' + someWord)\n",
    "def please(filepath, labels, n, someWord):\n",
    "    df_ori = pd.read_csv(filepath)\n",
    "    df_ori['cluster #'] = labels\n",
    "    #os.mkdir(os.getcwd() + '/' + someWord)\n",
    "    \n",
    "    \n",
    "    for cluster in range(n):\n",
    "        yes = df_ori[df_ori['cluster #'] == cluster]\n",
    "        filename = '{}/{}.csv'.format(someWord, str(cluster))\n",
    "        yes.to_csv(filename)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'woohoo2/0.csv'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-b947adf37692>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./org.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'woohoo1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./org.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'woohoo2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-31-186dfc1736e1>\u001b[0m in \u001b[0;36mplease\u001b[1;34m(filepath, labels, n, someWord)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0myes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_ori\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_ori\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cluster #'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcluster\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'{}/{}.csv'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msomeWord\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0myes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[0;32m   3168\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3169\u001b[0m         )\n\u001b[1;32m-> 3170\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3172\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m             f, handles = get_handle(\n\u001b[0m\u001b[0;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[0;32m    491\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'woohoo2/0.csv'"
     ]
    }
   ],
   "source": [
    "please('./org.csv',labels1,8,'woohoo1')\n",
    "\n",
    "please('./org.csv',labels2,8,'woohoo2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clustering the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "def nlp_clus(filename, n, desc=False):\n",
    "    df = pd.read_csv(filename)\n",
    "    # Instantiating the Vectorizer, experimenting with both\n",
    "    vectorizer = CountVectorizer()\n",
    "    #vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Fitting the vectorizer to the Bios\n",
    "    x = vectorizer.fit_transform(df['Bios'])\n",
    "\n",
    "    # Creating a new DF that contains the vectorized words\n",
    "    df_wrds = pd.DataFrame(x.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "    # Concating the words DF with the original DF\n",
    "    new_df = pd.concat([df, df_wrds], axis=1)\n",
    "\n",
    "    # Dropping the Bios because it is no longer needed in place of vectorization\n",
    "    new_df.drop('Bios', axis=1, inplace=True)\n",
    "\n",
    "    # Instantiating PCA\n",
    "    pca = PCA()\n",
    "\n",
    "    # Fitting and Transforming the DF\n",
    "    df_pca = pca.fit_transform(new_df)\n",
    "\n",
    "    # Reducing the dataset to the number of features determined before\n",
    "    pca = PCA(n_components=0.99)\n",
    "\n",
    "    # Fitting and transforming the dataset to the stated number of features and creating a new DF\n",
    "    df_pca = pca.fit_transform(new_df)\n",
    "\n",
    "    # Seeing the variance ratio that still remains after the dataset has been reduced\n",
    "    print(pca.explained_variance_ratio_.cumsum()[-1])\n",
    "    \n",
    "    labels = cluster(filename,n,False)\n",
    "    print(labels)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_cluster_for_cluster_spec(dir_spec):\n",
    "    dirname = '{}/{}'.format(os.getcwd(),dir_spec)\n",
    "    for filename in os.listdir(dirname):\n",
    "        labels = nlp_clus('{}/{}'.format(dirname, filename), 30, True)\n",
    "        print(labels)\n",
    "        please(dirname + '/' + filename,labels,n,'woohoo2_{}'.format(filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9981747004738313\n",
      "clus 30: 0.180151105914793, 0.672999141326298\n",
      "0.9982651981056483\n",
      "clus 30: 0.15232391786957933, 0.725581353397667\n",
      "0.9981442008155497\n",
      "clus 30: 0.1741889429681261, 0.5362327988439036\n",
      "0.9983595432185679\n",
      "clus 30: 0.13839222744535712, 0.5959971856299495\n",
      "0.9982374596075535\n",
      "clus 30: 0.12044924405918284, 0.6215699548175786\n",
      "0.9983426331134531\n",
      "clus 30: 0.1276324486307089, 0.6674295280822489\n",
      "0.9984505754157542\n",
      "clus 30: 0.1534592323538643, 0.7965288675278822\n",
      "0.9981950697614622\n",
      "clus 30: 0.08128846747879233, 0.5230269387787726\n"
     ]
    }
   ],
   "source": [
    "nlp_cluster_for_cluster_spec('./woohoo1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_cluster_for_cluster(dir_spec, n):\n",
    "    dirname = '{}/{}'.format(os.getcwd(),dir_spec)\n",
    "    for filename in os.listdir(dirname):\n",
    "        path = '{}/{}'.format(dirname, filename)\n",
    "        labels = nlp_clus(path, n, False)\n",
    "        print(labels)\n",
    "        please(dirname + '/' + filename,labels,n,'woohoo2_{}'.format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9980104220922025\nclus 18: 0.17562821788946123, 1.0713914464426784\n[11 12  1 17  1 11 17  4  7 10 12 13 13 13  4  0  4 10  1 11 15  2  4  4\n  0  3  7  1  0 14 14  2 10 13 15  2  8  9  2  8  3  9  5  5  9 16  6  0\n  6  3  5]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'woohoo2_0.csv/0.csv'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-a365adf5516f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnlp_cluster_for_cluster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./woohoo2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m18\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-75902f10883e>\u001b[0m in \u001b[0;36mnlp_cluster_for_cluster\u001b[1;34m(dir_spec, n)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp_clus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mplease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'woohoo2_{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-186dfc1736e1>\u001b[0m in \u001b[0;36mplease\u001b[1;34m(filepath, labels, n, someWord)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0myes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_ori\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_ori\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cluster #'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcluster\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'{}/{}.csv'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msomeWord\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0myes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[0;32m   3168\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3169\u001b[0m         )\n\u001b[1;32m-> 3170\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3172\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m             f, handles = get_handle(\n\u001b[0m\u001b[0;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\anaconda\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[0;32m    491\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'woohoo2_0.csv/0.csv'"
     ]
    }
   ],
   "source": [
    "nlp_cluster_for_cluster('./woohoo2', 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9985212170402835\n",
      "clus 2: 0.13858049565563965, 2.1936161295189107\n",
      "clus 3: 0.15087070774277922, 1.7586828648931403\n",
      "clus 4: 0.12243946881349771, 1.809400965643634\n",
      "clus 5: 0.13574382622533232, 1.6780404374681506\n",
      "clus 6: 0.14012023904481338, 1.6453631564153346\n",
      "clus 7: 0.1388077289930433, 1.625861177234928\n",
      "clus 8: 0.14288131176259566, 1.5027911054809222\n",
      "clus 9: 0.15262206673145318, 1.3943813217099086\n",
      "clus 10: 0.1561262732316628, 1.360371701042234\n",
      "clus 11: 0.16144817299148725, 1.273715017050711\n",
      "clus 12: 0.17537163778756346, 1.2199640128116724\n",
      "clus 13: 0.179115372525265, 1.20065026898033\n",
      "clus 14: 0.18356075279875603, 1.1631831463479088\n",
      "clus 15: 0.18701445882157214, 1.1325076339903102\n",
      "clus 16: 0.1799155379245125, 1.0806424377451105\n",
      "clus 17: 0.16842986934565896, 1.0338585820413417\n",
      "clus 18: 0.1673587612356257, 0.9616231609903498\n",
      "clus 19: 0.16354520289374772, 0.9194114469248651\n",
      "clus 20: 0.1616684607428307, 0.8950087351938262\n",
      "clus 21: 0.15846002473384774, 0.9048582626881111\n",
      "clus 22: 0.15580141843518258, 0.8693570595483471\n",
      "clus 23: 0.15452542139884792, 0.8631444140448646\n",
      "clus 24: 0.14772773796032895, 0.808129067621584\n",
      "clus 25: 0.14574880743210433, 0.7841730859336241\n",
      "clus 26: 0.13944323922555416, 0.7907442199368883\n",
      "clus 27: 0.13133967082505646, 0.7490854402913418\n",
      "clus 28: 0.1293817211172324, 0.6953325419828905\n",
      "clus 29: 0.1267110557027175, 0.6620908310026073\n",
      "0.9981113033590082\n",
      "clus 2: 0.12608419283256078, 2.3117814707637425\n",
      "clus 3: 0.11192515496505893, 2.0845380323996943\n",
      "clus 4: 0.13911577909129524, 1.8561038813408754\n",
      "clus 5: 0.14454502466089922, 1.6328442990115868\n",
      "clus 6: 0.16368112466043358, 1.474149943248559\n",
      "clus 7: 0.1620886119305774, 1.3706744989900623\n",
      "clus 8: 0.17091193215865905, 1.3324352832325583\n",
      "clus 9: 0.18434277981039487, 1.2177731649591432\n",
      "clus 10: 0.2059979623768807, 1.1521299801848548\n",
      "clus 11: 0.22316288928710323, 1.0975699676050856\n",
      "clus 12: 0.2189054379164483, 1.0819079028683793\n",
      "clus 13: 0.22363258405195302, 1.0376699675136287\n",
      "clus 14: 0.2329784423340262, 0.9915044016198814\n",
      "clus 15: 0.23503525480125845, 0.9464909087168412\n",
      "clus 16: 0.23700633286019382, 0.9292414472744812\n",
      "clus 17: 0.2317080747515486, 0.8633479709471404\n",
      "clus 18: 0.2245960660126046, 0.8268770058085149\n",
      "clus 19: 0.22054745343913645, 0.7826650233132666\n",
      "clus 20: 0.21154261591167453, 0.7383589475053297\n",
      "clus 21: 0.21227026045749683, 0.7081973586221834\n",
      "clus 22: 0.2033739661772603, 0.6753633797841857\n",
      "clus 23: 0.19779353595105983, 0.6269308509425892\n",
      "clus 24: 0.19025535310335034, 0.6016435379676758\n",
      "clus 25: 0.18308126347606216, 0.5585900555869958\n",
      "clus 26: 0.17525054533186593, 0.5430323184530225\n",
      "clus 27: 0.16845443678724717, 0.5241822095476746\n",
      "clus 28: 0.1639289509421291, 0.49017121870837327\n",
      "clus 29: 0.1570381110184144, 0.4588731709585014\n",
      "0.9982582121633528\n",
      "clus 2: 0.12378574527243848, 2.397564689338896\n",
      "clus 3: 0.11095423402222189, 2.0089048075398774\n",
      "clus 4: 0.13043210144154557, 1.8895312349666313\n",
      "clus 5: 0.12186651823803661, 1.7387193059728552\n",
      "clus 6: 0.11378380428848135, 1.8268077727858856\n",
      "clus 7: 0.11802133034232527, 1.7436172145369564\n",
      "clus 8: 0.1313619561671752, 1.6395895289311788\n",
      "clus 9: 0.1308881113601161, 1.544556247984079\n",
      "clus 10: 0.1281836960360546, 1.4739531776748815\n",
      "clus 11: 0.1406020250600312, 1.4113367431802901\n",
      "clus 12: 0.1421818727352101, 1.366050320684869\n",
      "clus 13: 0.14757600535006096, 1.3057232317756169\n",
      "clus 14: 0.14614635253594466, 1.2316121708625247\n",
      "clus 15: 0.14889260278369898, 1.2041966468624978\n",
      "clus 16: 0.1417878514901401, 1.2039521801323794\n",
      "clus 17: 0.14175737699219002, 1.158226170164701\n",
      "clus 18: 0.14821589719817846, 1.138809437248698\n",
      "clus 19: 0.15100727221028928, 1.103982873979708\n",
      "clus 20: 0.1554204888234202, 1.0543093154288172\n",
      "clus 21: 0.15712749819262936, 1.027688048639066\n",
      "clus 22: 0.15021100425024253, 0.998455328214878\n",
      "clus 23: 0.1464269161641441, 0.9582138227820719\n",
      "clus 24: 0.14228922415455544, 0.9310044690503254\n",
      "clus 25: 0.14244594763341445, 0.8893333675882643\n",
      "clus 26: 0.13905437314510324, 0.8558006809859299\n",
      "clus 27: 0.12916302570700264, 0.8146806898159338\n",
      "clus 28: 0.12602989631665412, 0.7942037957370806\n",
      "clus 29: 0.12188067446735225, 0.7745103304857245\n",
      "0.9979040017646877\n",
      "clus 2: 0.13539072812093642, 2.2287384725371937\n",
      "clus 3: 0.12364818908248969, 1.9910280210545672\n",
      "clus 4: 0.1581196866192558, 1.608509069273497\n",
      "clus 5: 0.15284972556379794, 1.7079162570035655\n",
      "clus 6: 0.1470414432551584, 1.6228264074179093\n",
      "clus 7: 0.14358259967777598, 1.5284194615281623\n",
      "clus 8: 0.14904386926271904, 1.3993633078235255\n",
      "clus 9: 0.16281157106589816, 1.4014992243654036\n",
      "clus 10: 0.16938960688968624, 1.281167698484316\n",
      "clus 11: 0.1893882700633696, 1.186285069115302\n",
      "clus 12: 0.17957712111196988, 1.2359858879654306\n",
      "clus 13: 0.16958882448483753, 1.1764997695666097\n",
      "clus 14: 0.16848510668218264, 1.090976617372349\n",
      "clus 15: 0.16394670074545664, 1.0378871057426862\n",
      "clus 16: 0.16639253310818064, 0.963602231112516\n",
      "clus 17: 0.1670706678528766, 0.9706926444689401\n",
      "clus 18: 0.1596679334129919, 0.9283787523823778\n",
      "clus 19: 0.15613105833935553, 0.8792038264325253\n",
      "clus 20: 0.1462462628030547, 0.8386022902568351\n",
      "clus 21: 0.13136874534875762, 0.8147230739841126\n",
      "clus 22: 0.1255639527446871, 0.7614783785922916\n",
      "clus 23: 0.119690064486173, 0.7393263000819712\n",
      "clus 24: 0.12587024725203416, 0.7054091119367363\n",
      "clus 25: 0.12473693046421423, 0.6860494041080685\n",
      "clus 26: 0.12395105921580152, 0.6358888434946883\n",
      "clus 27: 0.12399481419506117, 0.6061119366894707\n",
      "clus 28: 0.11861153053933848, 0.5457130553130941\n",
      "clus 29: 0.11137045920007256, 0.5109774056493205\n",
      "0.9980104220922025\n",
      "clus 2: 0.1244963373673966, 1.6730057819829394\n",
      "clus 3: 0.0895304103156297, 2.1272743808580894\n",
      "clus 4: 0.11700678277990019, 2.0003547928990617\n",
      "clus 5: 0.13132830888520455, 1.7883286422657956\n",
      "clus 6: 0.12913214911291995, 1.629895870999918\n",
      "clus 7: 0.1351955322179452, 1.5308197317506913\n",
      "clus 8: 0.1438586914811485, 1.5873453051269213\n",
      "clus 9: 0.14976517652920132, 1.4741316368503692\n",
      "clus 10: 0.15362344770155084, 1.3715948286617383\n",
      "clus 11: 0.15067407467534846, 1.37046826210441\n",
      "clus 12: 0.1535753690354724, 1.344678636225904\n",
      "clus 13: 0.16493908275126862, 1.294553293266023\n",
      "clus 14: 0.16737713731697482, 1.2513842076366561\n",
      "clus 15: 0.1665641770734743, 1.2321116574772446\n",
      "clus 16: 0.17308541432362232, 1.2026027362695237\n",
      "clus 17: 0.17006532297299543, 1.1154758303486132\n",
      "clus 18: 0.17562821788946123, 1.0713914464426784\n",
      "clus 19: 0.17438365116955543, 1.0434777441325302\n",
      "clus 20: 0.17050600548872155, 0.997771623328647\n",
      "clus 21: 0.16278017513673615, 0.9584363522573541\n",
      "clus 22: 0.16252399392569145, 0.94951929924658\n",
      "clus 23: 0.1620166043561299, 0.9147769027825635\n",
      "clus 24: 0.15909460887401397, 0.8769410469976245\n",
      "clus 25: 0.15002877587609498, 0.8727813210089743\n",
      "clus 26: 0.15096921162873056, 0.8435053182783135\n",
      "clus 27: 0.14849065132012446, 0.8014829670600967\n",
      "clus 28: 0.1496229531450112, 0.7725205529815258\n",
      "clus 29: 0.140316814739015, 0.7545573241568186\n",
      "0.9982502532681795\n",
      "clus 2: 0.13170899042772483, 2.245272360946492\n",
      "clus 3: 0.12650709026857798, 1.9965758873191202\n",
      "clus 4: 0.10653442684016586, 1.8804171033108883\n",
      "clus 5: 0.11767780122398021, 1.6939725215459938\n",
      "clus 6: 0.12545208003095126, 1.6290583445414806\n",
      "clus 7: 0.13356060069966175, 1.5697519757335388\n",
      "clus 8: 0.1376608237340527, 1.469325488602128\n",
      "clus 9: 0.13731467362848557, 1.50249882197478\n",
      "clus 10: 0.14049160106635045, 1.4330763379005793\n",
      "clus 11: 0.14643556943821898, 1.3763647095066105\n",
      "clus 12: 0.15273007877898756, 1.3530463931824819\n",
      "clus 13: 0.1649376249321876, 1.2947428271469816\n",
      "clus 14: 0.16435522644955441, 1.2924956762513269\n",
      "clus 15: 0.1658299447800002, 1.2008195606780754\n",
      "clus 16: 0.16887721927067886, 1.1588599430566013\n",
      "clus 17: 0.1705482513007121, 1.1208866819342767\n",
      "clus 18: 0.1674426798770597, 1.1282789119757395\n",
      "clus 19: 0.17095363560359253, 1.0920206611957384\n",
      "clus 20: 0.17358171036801684, 1.0539458601875193\n",
      "clus 21: 0.18083155584820626, 1.0073325017642654\n",
      "clus 22: 0.1785189885646527, 0.9690669023390562\n",
      "clus 23: 0.17763272251528334, 0.9578704787467526\n",
      "clus 24: 0.1751650927061432, 0.9096271810417408\n",
      "clus 25: 0.17664196089900025, 0.8808831633196036\n",
      "clus 26: 0.17057915576558566, 0.8460591819923118\n",
      "clus 27: 0.16727457350630623, 0.8217308280544358\n",
      "clus 28: 0.1666412825217387, 0.7767314716318285\n",
      "clus 29: 0.1643452787860107, 0.7308117122147156\n",
      "0.9984318566685374\n",
      "clus 2: 0.12996157831058358, 2.360325798555381\n",
      "clus 3: 0.13973864343212436, 1.9751511378792854\n",
      "clus 4: 0.13508664856837296, 1.694272700841219\n",
      "clus 5: 0.11778088082092152, 1.7985176541531203\n",
      "clus 6: 0.11611991427242091, 1.768251863174946\n",
      "clus 7: 0.11695025819200441, 1.713293930509377\n",
      "clus 8: 0.11835075225252542, 1.6070181877521754\n",
      "clus 9: 0.1334852542140417, 1.5285520256130036\n",
      "clus 10: 0.13823179851377138, 1.4802823652268677\n",
      "clus 11: 0.15423916024242734, 1.3792159202617793\n",
      "clus 12: 0.16665074842652233, 1.3019620239396181\n",
      "clus 13: 0.1767961334378421, 1.2127880694601387\n",
      "clus 14: 0.17900049456552145, 1.1859546800569631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clus 15: 0.17605843728041998, 1.0746654254141328\n",
      "clus 16: 0.17700735643443177, 1.0456554175208326\n",
      "clus 17: 0.17600874666330432, 1.0237864451609777\n",
      "clus 18: 0.17628125780901366, 0.9745863828167081\n",
      "clus 19: 0.17432860973134218, 0.9743116434036269\n",
      "clus 20: 0.16745464021267198, 0.9439466647925272\n",
      "clus 21: 0.16482447780233508, 0.9356984139580968\n",
      "clus 22: 0.16832221932493918, 0.9299299987194839\n",
      "clus 23: 0.16178254222920552, 0.9024901071319817\n",
      "clus 24: 0.15567417972649655, 0.851871841650972\n",
      "clus 25: 0.14985203913024853, 0.8245177063913846\n",
      "clus 26: 0.14430402682074997, 0.7699048252956077\n",
      "clus 27: 0.13729143500172708, 0.7318953345808223\n",
      "clus 28: 0.12825950214822662, 0.6969154588020572\n",
      "clus 29: 0.11923356580669509, 0.6722571517883678\n",
      "0.9983748341350666\n",
      "clus 2: 0.11408908515241749, 2.288556134649239\n",
      "clus 3: 0.12022012284017967, 2.0478873445836023\n",
      "clus 4: 0.09495813892753023, 1.9779710252233675\n",
      "clus 5: 0.10630740382944338, 1.7995815390601984\n",
      "clus 6: 0.11859619236098916, 1.7655465671911454\n",
      "clus 7: 0.12964683184725984, 1.6691332094440496\n",
      "clus 8: 0.13807158345012152, 1.6144295357108431\n",
      "clus 9: 0.12990456865718059, 1.5897106675387849\n",
      "clus 10: 0.13422118442554834, 1.5306638814289726\n",
      "clus 11: 0.14109763937197453, 1.4708705276907472\n",
      "clus 12: 0.14932336870252172, 1.4257210375467586\n",
      "clus 13: 0.15528020222751235, 1.3370001954917035\n",
      "clus 14: 0.16331603232742084, 1.3126407480334303\n",
      "clus 15: 0.16616093595871803, 1.2729742164263889\n",
      "clus 16: 0.17141597432440842, 1.2776197757033634\n",
      "clus 17: 0.18468075859013242, 1.2331968155838684\n",
      "clus 18: 0.18180103464969535, 1.1895812608402205\n",
      "clus 19: 0.18606711806488485, 1.1447112140539903\n",
      "clus 20: 0.1810157016130864, 1.179528672293167\n",
      "clus 21: 0.17699369242443977, 1.145695737953345\n",
      "clus 22: 0.17606136227309185, 1.1009613213397609\n",
      "clus 23: 0.17686946033364417, 1.0827685506290816\n",
      "clus 24: 0.17731894372818535, 1.0651098630346947\n",
      "clus 25: 0.1787664933813579, 1.032265390533979\n",
      "clus 26: 0.1778358319994981, 0.9974355311205104\n",
      "clus 27: 0.17799370713987112, 0.9486568047305899\n",
      "clus 28: 0.17792080048967807, 0.8996457945821161\n",
      "clus 29: 0.17256918403997476, 0.873467315675014\n"
     ]
    }
   ],
   "source": [
    "nlp_cluster_for_cluster_spec('./woohoo2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}